import streamlit as st
import os
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI

# --- 1. í™˜ê²½ ì„¤ì • ë° API í‚¤ í™•ì¸ ---
def setup_environment():
    """Streamlit Secretsì—ì„œ API í‚¤ë¥¼ ì„¤ì •í•˜ê³  ë¡œë“œí•©ë‹ˆë‹¤."""
    # OpenAI API í‚¤ëŠ” Streamlit Secrets(ë˜ëŠ” os.environ)ì— 'OPENAI_API_KEY'ë¡œ ì €ì¥ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    # ì‚¬ìš©ìì—ê²Œ API í‚¤ ì…ë ¥ì„ ìœ ë„í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.
    openai_api_key = st.sidebar.text_input("OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”:", type="password")
    
    if openai_api_key:
        os.environ["OPENAI_API_KEY"] = openai_api_key
        return True
    return False

# --- 2. RAG ì‹œìŠ¤í…œ í•µì‹¬ í•¨ìˆ˜ ---
def create_rag_chain(pdf_path):
    """
    PDF íŒŒì¼ ê²½ë¡œë¥¼ ë°›ì•„ LangChainì„ ì´ìš©í•œ RAG ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    st.info("ğŸ“š ìë£Œ(PDF)ë¥¼ ì½ê³  AIê°€ í•™ìŠµ(ìƒ‰ì¸)í•˜ëŠ” ì¤‘...", icon="â³")
    
    # 1. ë¬¸ì„œ ë¡œë“œ (PyPDFLoader ì‚¬ìš©)
    loader = PyPDFLoader(pdf_path)
    documents = loader.load()
    
    # 2. í…ìŠ¤íŠ¸ ë¶„í•  (ì²­í¬ ìƒì„±)
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len
    )
    texts = text_splitter.split_documents(documents)
    
    # 3. ì„ë² ë”© ë° ë²¡í„° ì €ì¥ì†Œ ìƒì„± (FAISS ì‚¬ìš©)
    embeddings = OpenAIEmbeddings()
    vectorstore = FAISS.from_documents(texts, embeddings)
    
    # 4. LLM ëª¨ë¸ ì„¤ì • (ChatOpenAI)
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
    
    # 5. RAG ì²´ì¸ ìƒì„± (RetrievalQA)
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=vectorstore.as_retriever(),
        return_source_documents=False # ì†ŒìŠ¤ ë¬¸ì„œ ë°˜í™˜ ì—¬ë¶€
    )
    
    st.success("âœ… í•™ìŠµ ì™„ë£Œ! ì´ì œ ì§ˆë¬¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    return qa_chain

# --- 3. Streamlit ì•± ë©”ì¸ ë¡œì§ ---
def main():
    st.set_page_config(page_title="ë†ì—…íšŒì‚¬ë²•ì¸ RAG ì±—ë´‡", layout="wide")
    st.title("ğŸŒ± ë†ì—…íšŒì‚¬ë²•ì¸ ë° ë†ì§€ë²• ì „ë¬¸ AI ì±—ë´‡")
    st.markdown("---")

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (RAG ì²´ì¸ ë° API í‚¤ ìƒíƒœ ì €ì¥)
    if 'rag_chain' not in st.session_state:
        st.session_state['rag_chain'] = None
    if 'api_key_valid' not in st.session_state:
        st.session_state['api_key_valid'] = False

    # API í‚¤ ì„¤ì •
    st.session_state['api_key_valid'] = setup_environment()
    
    # íŒŒì¼ ì—…ë¡œë“œ (ì—¬ê¸°ì„œëŠ” Streamlitì„ í†µí•´ íŒŒì¼ì„ ë°›ì•„ ë°”ë¡œ ì²˜ë¦¬)
    # ì‹¤ì œ ë°°í¬ ì‹œì—ëŠ” GitHubì— ì—…ë¡œë“œëœ íŒŒì¼ì„ ì§ì ‘ ë¡œë“œí•˜ëŠ” ì½”ë“œë¡œ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤.
    uploaded_file = st.sidebar.file_uploader(
        "ğŸ“ ë†ì—… ê´€ë ¨ PDF ìë£Œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.",
        type=["pdf"],
        disabled=not st.session_state['api_key_valid']
    )

    if uploaded_file and st.session_state['api_key_valid']:
        # ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„ì‹œ ì €ì¥í•˜ê³  ê²½ë¡œë¥¼ ë„˜ê²¨ì¤Œ
        with open("uploaded_doc.pdf", "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        # RAG ì²´ì¸ ìƒì„±
        if st.session_state['rag_chain'] is None:
            st.session_state['rag_chain'] = create_rag_chain("uploaded_doc.pdf")
            
        # --- ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ---
        if "messages" not in st.session_state:
            st.session_state["messages"] = [{"role": "assistant", "content": "ë†ì—…íšŒì‚¬ë²•ì¸ ì„¤ë¦½, ë†ì§€ ì·¨ë“ ë“± ê¶ê¸ˆí•œ ì ì„ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”!"}]

        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.chat_message("assistant"):
                with st.spinner("AIê°€ ìë£Œë¥¼ ê²€ìƒ‰í•˜ê³  ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                    # RAG ì²´ì¸ í˜¸ì¶œ
                    response = st.session_state['rag_chain'].invoke(prompt)
                    st.markdown(response['result'])
                
                st.session_state.messages.append({"role": "assistant", "content": response['result']})

    elif not st.session_state['api_key_valid']:
        st.warning("ğŸ”‘ ê³„ì†í•˜ë ¤ë©´ OpenAI API Keyë¥¼ ì‚¬ì´ë“œë°”ì— ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    else:
        st.warning("ì—…ë¡œë“œëœ PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë†ì—… ë²•ê·œ ìë£Œ(PDF)ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()
